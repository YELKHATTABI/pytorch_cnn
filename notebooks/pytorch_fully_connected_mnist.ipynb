{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "pytorch is a python library for deep learning. It is built on top of the CPU and GPU.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install torch\n",
    "```\n",
    "\n",
    "## Import\n",
    "\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "\n",
    "With pytorch you can create a model and train it. You can also create datasets object and iterate over them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_flatten_normalize(image: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"flattens the image tensor\n",
    "    \"\"\"\n",
    "    image = image.flatten() # flatten the image for a multi-dimensional input to a vecture of shape (1, 28*28)\n",
    "    image = image.float() # convert the flattened image to a float tensor to be able to normalize it\n",
    "    \n",
    "    # normalize the image to be between 0 and 1 we devide by 255 because the image is in the range of 0 to 255\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "def read_image_torch(image_path: str) -> torch.Tensor:\n",
    "    \"\"\"reads the image from the path and returns a tensor\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    array_image = np.array(image)\n",
    "    return torch.as_tensor(array_image)\n",
    "\n",
    "# def tranform_label_to_one_hot(label:int):\n",
    "#     \"\"\"transforms the label to a one hot vector of shape (1, 10) because we have 10 classes\n",
    "#     \"\"\"\n",
    "#     return torch.tensor(label, dtype=torch.f)\n",
    "\n",
    "def read_image_to_labels_file(annotations_file: str, train: bool) -> pd.DataFrame:\n",
    "    img_labels = pd.read_csv(annotations_file)\n",
    "    img_labels = img_labels[img_labels['train'] == train]\n",
    "    return img_labels\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    \"\"\"A Pytorch Dataset class for the MNIST dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, annotations_file, images_folder, train, transform=None, target_transform=None):\n",
    "        self.img_labels = read_image_to_labels_file(annotations_file, train)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    # we always need to define the __len__ method for the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    # we always need to define the __getitem__ method for the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_folder, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image_torch(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_no_transform_dataset = MnistDataset(\n",
    "    annotations_file=\"../data/mnist/mnist.csv\",\n",
    "    images_folder=\"../data/mnist\",\n",
    "    train=True,\n",
    "    transform=transform_flatten_normalize,\n",
    "    target_transform=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loaders with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset(\n",
    "    annotations_file=\"../data/mnist/mnist.csv\", \n",
    "    images_folder=\"../data/mnist/\", \n",
    "    train=True, \n",
    "    transform=transform_flatten_normalize, \n",
    "    target_transform=None,\n",
    ")\n",
    "test_dataset = MnistDataset(\n",
    "    annotations_file=\"../data/mnist/mnist.csv\", \n",
    "    images_folder=\"../data/mnist/\", \n",
    "    train=False, \n",
    "    transform=transform_flatten_normalize, \n",
    "    target_transform=None,\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fully connected layer pytorch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class VerySimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "# Evaluate the performance of the neural network\n",
    "def evaluate(net, test_dataloader):\n",
    "    ground_truths = []\n",
    "    predictions = []\n",
    "    net = net.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        eval_loss = 0\n",
    "        for x, y in tqdm(test_dataloader):\n",
    "            x = x\n",
    "            y_pred = net(x)\n",
    "            predicted = y_pred.argmax(dim=1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            eval_loss += F.cross_entropy(y_pred, y, reduction='sum').item()\n",
    "            ground_truths.extend(y.tolist())\n",
    "            predictions.extend(predicted.tolist())\n",
    "        accuracy = correct / total\n",
    "        eval_loss = eval_loss / total\n",
    "        print(f'Eval Loss: {eval_loss}')\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "        \n",
    "    net = net.train()\n",
    "    return ground_truths, predictions, accuracy, eval_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_simple_net = VerySimpleNet()\n",
    "# train very_simple_net\n",
    "\n",
    "learning_rate = 0.001 # to be tuned\n",
    "optimizer = torch.optim.Adam(very_simple_net.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "summary_writer = SummaryWriter(log_dir='./runs/pytorch_fully_connected_mnist')\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    accumulated_loss = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        # for each iteration, I get a batch of images of size (batch size 100) and a batch of labels\n",
    "        \n",
    "        y_pred = very_simple_net(x)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        accumulated_loss += loss.item()\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'------- Epoch {epoch + 1}: Train Loss {accumulated_loss/len(train_dataloader)}')\n",
    "    _, _, eval_acc, eval_loss = evaluate(very_simple_net, test_dataloader)\n",
    "    summary_writer.add_scalars('Loss', {'train': accumulated_loss/len(train_dataloader), 'eval': eval_loss}, epoch)\n",
    "    summary_writer.add_scalars('Accuracy', {'eval': eval_acc}, epoch)\n",
    "\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = SimpleNet()\n",
    "# train simple_net\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(simple_net.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 40\n",
    "simple_net = simple_net.to('cuda')\n",
    "for epoch in range(num_epochs):\n",
    "    accumulated_loss = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        x = x.to('cuda')\n",
    "        y = y.to('cuda')\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = simple_net(x)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accumulated_loss += loss.item()\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'------Epoch {epoch + 1}: Train Loss {accumulated_loss/len(train_dataloader)}')\n",
    "    evaluate(simple_net, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "ground_truths, predictions = evaluate(very_simple_net, test_dataloader)\n",
    "ConfusionMatrixDisplay.from_predictions(ground_truths, predictions)\n",
    "plt.show()\n",
    "print(classification_report(ground_truths, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths, predictions = evaluate(simple_net, test_dataloader)\n",
    "ConfusionMatrixDisplay.from_predictions(ground_truths, predictions)\n",
    "plt.show()\n",
    "print(classification_report(ground_truths, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
